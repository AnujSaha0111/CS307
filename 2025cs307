Autumn 2025-26
CS307
Class Meet link:
https://meet.google.com/ejt-zsdr-eeb

05/08/2025
Lec 1

Toy examples
(1) 3 Jugs - 8lt, 5lt, 3lt -> Measure 4lt (conserve water)
(2) Missionaries and Cannibals - 3 Miss, 3 Cann on left bank -> transfer to right bank
A boat with max capacity 2 
(3) Knuth - Sqrt, !, Floor - Start at 5 -> reach 7

Introduction to the course
Module 1: Introduction to AI and Search [6 Hour]
History, The state of the art; intelligent agents; structure; environment; Configuration and Planning Problems, State space representation, Breadth-first search; uniform cost search; depth-first search; depth-limited search; iterative, deepening search; bi-directional search; heuristic search techniques; comparing search strategies, randomized search, adversarial search, alpha-beta pruning

Module 2: Probabilistic Reasoning [12 Hours]
Non-monotonic reasoning; logics; implementation; probability and Bayes theorem; certainty factors; Bayesian networks (Graphical Models), Markov Networks; Hidden Markov Model, Decision Tree and Random Forest

Module 3: Neural Networks [9 Hours]
Neuron as a nonlinear combiner, Capacity of a single neuron, Feed-forward networks and Universal Approximation Theorem, Hopfield Network and Associative Memory

Module 4: Reinforcement Learning and Computational Game Theory [12 Hours]
Markov Decision Process, Reinforcement Learning, Extensive form games, Social Choice and Mechanism Design

Story of halwai making laddoos
Progression of a sequence 1 2 3 4 ... to 2^n

Reality check
Information consumes attention (may be the measure of information can be defined
attention that it consumes rather than the entropic one!)

Evaluation Policy
Quizzes, Projects, Peer Assessment, 
Project report submissions - one before in-sem and the other before end-sem exams

07/08/2025
Lec 2

ChatGPT Example:
Immersive Technologies and Cognitive Systems in Hindi
✅ Simplified Hindi (For broader understanding):
"डूबाने वाली तकनीकें और सोचने-समझने वाली प्रणालियाँ"
(Doobāne Vālī Taknīken aur Sochne-Samajhne Vālī Praṇāliyān)

3 Jugs Problem:
Configuration -> State -> [8, 0, 0] Index 0, 1, 2 -> 8,5,3 lt jugs resp.
Init_State = [8,0,0]
Goal_State = [4,1,3], [4,4,0], [4,2,2], [4,3,1], ...

Agent                           Environment/ Problem
Init_State
Push(Init_State, Frontier)
Node <- Pop(Frontier)
bool Is_Goal(Node.State)
                                List <- Get_Successor(State)
Pick one Node from List
Node.State in Visited?
Pick another Node from List
...
Node.State in Frontier?
Replace/ Keep Cond. Value
...
Frontier <- push(Node)
Pop Node from Frontier
bool Is_Goal(Succ)

(8,0,0)->(3,5,0)->(3,2,3)->
(6,2,0)->(6,0,2)->(1,5,2)->
(3,5,0)

[[3,5,0],1,[8,0,0]]
[[3,5,0],6,[1,5,2]]

Breadth First Search

Node_under_cons         Frontier(FIFO)          Visited
[[8,0,0],0,{}]          [[8,0,0],0,{}]                  
                                                [[8,0,0],0,{}]              
                        [[3,5,0],1,[8,0,0]]
                        [[5,0,3],1,[8,0,0]]
[[3,5,0],1,[8,0,0]]                             [[8,0,0],0,{}]
                                                [[3,5,0],1,[8,0,0]] 
                        [[5,0,3],1,[8,0,0]]
                        [[0,5,3],2,[3,5,0]]
                        [[3,2,3],2,[3,5,0]]

12/08/2025
Lec 3

Flatland - Romance of many dimensions
Edwin Abott

GIT: pratikiiitv/cs307
three_jugs_bfs.py

Puzzle-8 Problem
Size of state space? 
Informed Search : Heuristic function
value function of a node 
f(node) = g(node) + h(node)
g - actual distance of node from the initial state
h - estimated distance to goal from the current node

12/08/2025
Lab 1 (S2, S1/S3)
Demonstration of Puzzle-8 BFS/ DFS

14/08/2025
Lec 4
Informed Search Agent
Heuristic Function
f = g + h
f : {set of nodes} -> \mathbb{R}^+
How to design h?

(1) Relaxed problem
Movement not restricted to plane!
[1 2 3 4 5 6 7 8 0] -> [0 2 3 4 5 6 7 8 1]
Init -> Goal
h(n) = number of misplaced tiles

(2) Effort required to solve partially/ subproblem
[1 2 3 4 * * * * 0] -> [0 2 3 4 * * * * 1]

(3) Landmarks {L_i}i\in I
d(n, L_i), \forall n
Init -> Goal
h(Init) = min_i {d(Init,L_i) + d(L_i, Goal)}

Heuristic function - underestimates the actual distance to 
goal - the search agent with forntier prioritized by 
f=g+h will always return an optimal path (if it exists) to
the goal state.

"A-star" 

Search Agent/ Algorithm attributes
1. Completeness
2. Optimality
3. Complexity - Time/ Space

BFS - b-branching factor is finite and solution is at a finite
depth BFS is complete, BFS is optimal
DFS - is not complete - is not optimal
A-star - is complete and optimal

Admissible Heuristic - h(n) <= d(n,G), \forall n

Proof by contradiction:
Let us assume that the solution that the agent returns is not
optimal and the length is C. The heuristic function used is 
admissible. h(.) <= d(.,Goal) 

Let the optimal distance from Init to Goal is C*
C > C*
\exists n on optimal path in frontier which was not popped!
f(n) = g(n) + h(n) > C ---(1)
but h(n) <= C* - g(n) ---(2)/ admissibility of heuristic h
=><= Contradiction!

Quiz 2:
variants : f = w1*g+w2*hi
Find path from S to G using h1 - Manhattan Distance 
Find path from S to G using h2 - Euclidean Distance 
w1 = 1, w2 = 0 (Dijkstra)
w1 = w2 = 1 (A*)
w1 = 0, w2 = 1 (Greedy search agent)

18/08/2025
Lec 5

Local Search
(S, N, f)
S: Set of states
N: Neighborhood defination
f: Objective function f:S->\mathbb{R}
find s*\in S, s.t. f(s*) <= f(s), \forall s\in S
s* is referred to as minimum.

init s_old
for neighbor s in neighborhood (s_old)
    if f(s) <= f(s_old) then return s_old = s
    return s_old as minumum

s\in N(s_old)
f(s) <= f(s_old) then accept s as a better state

Metropolis Algorithm
1953 Metropolis, Rosenbluth, Teller
Simulated Annealing

s\in N(s_old)
f(s) <= f(s_old) then accept s as a better state

even if f(s) > f(s_old)
accept s as the next state to explore from with
a probability p = exp[-(f(s)-f(s_old))/c]

It is like a random walk in the state space S
s_0, s_1, s_2, s_3, s_4, ..., s_(N-1)

p(s) = (#s_i==s)/N \proportional exp[-f(s)]

Ex. Knapsack

Ex. TSP

Ex. Decoding substitution cypher
Language Model - Dasher, David McKay
https://www.inference.org.uk/dasher/

Piece of text in English Language
x_0, x_1, x_2, ..., x_(N-1)

LM := P(x_i+1 | x_i ) - state transition probability
P(x_i+1 | x_i, x_i-1, x_i-2, ..., x_0) = P(x_i+1 | x_i )
Markovian assumption

P(x_0, x_1, x_2, ..., x_(N-1) | LM) - Likelihood
= P(x_1 | LM) P(x_1 | x_0, LM) ... P(x_N-1 | x_N-2, LM)

log(P(\product_i x_i|LM)) = \sum log(P(x_i+1 | x_i, LM))
Log-Likelihood!

21/08/2025
Lec 6

Advanced Topics:
Exploiting Symmetry in Graph Search
a         h
 \       / 
  b     g     
   \   /
    c-f          ~       S1-S2-S3-S4-S5
   /   \
  d     i  
 /       \
e         j  
Symmetries captured by automorphism group
Orbit-Stabilizer
Very interesting insights
Graph compression

Adversarial Search:













Exercise: MINIMAX Agent  
Max
                               /           \
Min  
               /           \                   /           \
Max  
           /   \           /   \           /   \           /   \
Min
        / \     / \     / \     / \     / \     / \     / \     / \
leaf   8   7   5   6   4   3   2   7   7   5   6   4   3   2   7   8


Exercise: Any saving possible?


            /       |       \

     /  |  \     /  |  \     /  |  \
    3   12  8   2   4   6   14  5   2

Exercise: (branching factor = 2)

Leaf    10  5   7   11  12  8   9   8   5   12  11  12  9   8   7   10

Exercise: Quiz-3

Leaf    10  7   8   9   12  11  12  5   8   9   8   12  11  7   5   10


Lec 7
Probabilistic Graphical Models


Advanced Topics:
Lifted Inference in PGMs

