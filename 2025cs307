Autumn 2025-26
CS307
Class Meet link:
https://meet.google.com/ejt-zsdr-eeb

05/08/2025
Lec 1

Toy examples
(1) 3 Jugs - 8lt, 5lt, 3lt -> Measure 4lt (conserve water)
(2) Missionaries and Cannibals - 3 Miss, 3 Cann on left bank -> transfer to right bank
A boat with max capacity 2 
(3) Knuth - Sqrt, !, Floor - Start at 5 -> reach 7

Introduction to the course
Module 1: Introduction to AI and Search [6 Hour]
History, The state of the art; intelligent agents; structure; environment; Configuration and Planning Problems, State space representation, Breadth-first search; uniform cost search; depth-first search; depth-limited search; iterative, deepening search; bi-directional search; heuristic search techniques; comparing search strategies, randomized search, adversarial search, alpha-beta pruning

Module 2: Probabilistic Reasoning [12 Hours]
Non-monotonic reasoning; logics; implementation; probability and Bayes theorem; certainty factors; Bayesian networks (Graphical Models), Markov Networks; Hidden Markov Model, Decision Tree and Random Forest

Module 3: Neural Networks [9 Hours]
Neuron as a nonlinear combiner, Capacity of a single neuron, Feed-forward networks and Universal Approximation Theorem, Hopfield Network and Associative Memory

Module 4: Reinforcement Learning and Computational Game Theory [12 Hours]
Markov Decision Process, Reinforcement Learning, Extensive form games, Social Choice and Mechanism Design

Story of halwai making laddoos
Progression of a sequence 1 2 3 4 ... to 2^n

Reality check
Information consumes attention (may be the measure of information can be defined
attention that it consumes rather than the entropic one!)

Evaluation Policy
Quizzes, Projects, Peer Assessment, 
Project report submissions - one before in-sem and the other before end-sem exams

07/08/2025
Lec 2

ChatGPT Example:
Immersive Technologies and Cognitive Systems in Hindi
✅ Simplified Hindi (For broader understanding):
"डूबाने वाली तकनीकें और सोचने-समझने वाली प्रणालियाँ"
(Doobāne Vālī Taknīken aur Sochne-Samajhne Vālī Praṇāliyān)

3 Jugs Problem:
Configuration -> State -> [8, 0, 0] Index 0, 1, 2 -> 8,5,3 lt jugs resp.
Init_State = [8,0,0]
Goal_State = [4,1,3], [4,4,0], [4,2,2], [4,3,1], ...

Agent                           Environment/ Problem
Init_State
Push(Init_State, Frontier)
Node <- Pop(Frontier)
bool Is_Goal(Node.State)
                                List <- Get_Successor(State)
Pick one Node from List
Node.State in Visited?
Pick another Node from List
...
Node.State in Frontier?
Replace/ Keep Cond. Value
...
Frontier <- push(Node)
Pop Node from Frontier
bool Is_Goal(Succ)

(8,0,0)->(3,5,0)->(3,2,3)->
(6,2,0)->(6,0,2)->(1,5,2)->
(3,5,0)

[[3,5,0],1,[8,0,0]]
[[3,5,0],6,[1,5,2]]

Breadth First Search

Node_under_cons         Frontier(FIFO)          Visited
[[8,0,0],0,{}]          [[8,0,0],0,{}]                  
                                                [[8,0,0],0,{}]              
                        [[3,5,0],1,[8,0,0]]
                        [[5,0,3],1,[8,0,0]]
[[3,5,0],1,[8,0,0]]                             [[8,0,0],0,{}]
                                                [[3,5,0],1,[8,0,0]] 
                        [[5,0,3],1,[8,0,0]]
                        [[0,5,3],2,[3,5,0]]
                        [[3,2,3],2,[3,5,0]]

12/08/2025
Lec 3

Flatland - Romance of many dimensions
Edwin Abott

GIT: pratikiiitv/cs307
three_jugs_bfs.py

Puzzle-8 Problem
Size of state space? 
Informed Search : Heuristic function
value function of a node 
f(node) = g(node) + h(node)
g - actual distance of node from the initial state
h - estimated distance to goal from the current node

12/08/2025
Lab 1 (S2, S1/S3)
Demonstration of Puzzle-8 BFS/ DFS

14/08/2025
Lec 4
Informed Search Agent
Heuristic Function
f = g + h
f : {set of nodes} -> \mathbb{R}^+
How to design h?

(1) Relaxed problem
Movement not restricted to plane!
[1 2 3 4 5 6 7 8 0] -> [0 2 3 4 5 6 7 8 1]
Init -> Goal
h(n) = number of misplaced tiles

(2) Effort required to solve partially/ subproblem
[1 2 3 4 * * * * 0] -> [0 2 3 4 * * * * 1]

(3) Landmarks {L_i}i\in I
d(n, L_i), \forall n
Init -> Goal
h(Init) = min_i {d(Init,L_i) + d(L_i, Goal)}

Heuristic function - underestimates the actual distance to 
goal - the search agent with forntier prioritized by 
f=g+h will always return an optimal path (if it exists) to
the goal state.

"A-star" 

Search Agent/ Algorithm attributes
1. Completeness
2. Optimality
3. Complexity - Time/ Space

BFS - b-branching factor is finite and solution is at a finite
depth BFS is complete, BFS is optimal
DFS - is not complete - is not optimal
A-star - is complete and optimal

Admissible Heuristic - h(n) <= d(n,G), \forall n

Proof by contradiction:
Let us assume that the solution that the agent returns is not
optimal and the length is C. The heuristic function used is 
admissible. h(.) <= d(.,Goal) 

Let the optimal distance from Init to Goal is C*
C > C*
\exists n on optimal path in frontier which was not popped!
f(n) = g(n) + h(n) > C ---(1)
but h(n) <= C* - g(n) ---(2)/ admissibility of heuristic h
=><= Contradiction!

Quiz 2:
variants : f = w1*g+w2*hi
Find path from S to G using h1 - Manhattan Distance 
Find path from S to G using h2 - Euclidean Distance 
w1 = 1, w2 = 0 (Dijkstra)
w1 = w2 = 1 (A*)
w1 = 0, w2 = 1 (Greedy search agent)

